{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Movie Reviews dataset of nltk library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the moview_reviews from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LazyCorpusLoader in module nltk.corpus.util object:\n",
      "\n",
      "movie_reviews = class LazyCorpusLoader(builtins.object)\n",
      " |  movie_reviews(name, reader_cls, *args, **kwargs)\n",
      " |  \n",
      " |  To see the API documentation for this lazily loaded corpus, first\n",
      " |  run corpus.ensure_loaded(), and then run help(this_corpus).\n",
      " |  \n",
      " |  LazyCorpusLoader is a proxy object which is used to stand in for a\n",
      " |  corpus object before the corpus is loaded.  This allows NLTK to\n",
      " |  create an object for each corpus, but defer the costs associated\n",
      " |  with loading those corpora until the first time that they're\n",
      " |  actually accessed.\n",
      " |  \n",
      " |  The first time this object is accessed in any way, it will load\n",
      " |  the corresponding corpus, and transform itself into that corpus\n",
      " |  (by modifying its own ``__class__`` and ``__dict__`` attributes).\n",
      " |  \n",
      " |  If the corpus can not be found, then accessing this object will\n",
      " |  raise an exception, displaying installation instructions for the\n",
      " |  NLTK data package.  Once they've properly installed the data\n",
      " |  package (or modified ``nltk.data.path`` to point to its location),\n",
      " |  they can then use the corpus object without restarting python.\n",
      " |  \n",
      " |  :param name: The name of the corpus\n",
      " |  :type name: str\n",
      " |  :param reader_cls: The specific CorpusReader class, e.g. PlaintextCorpusReader, WordListCorpusReader\n",
      " |  :type reader: nltk.corpus.reader.api.CorpusReader\n",
      " |  :param nltk_data_subdir: The subdirectory where the corpus is stored.\n",
      " |  :type nltk_data_subdir: str\n",
      " |  :param *args: Any other non-keywords arguments that `reader_cls` might need.\n",
      " |  :param *kargs: Any other keywords arguments that `reader_cls` might need.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getattr__(self, attr)\n",
      " |  \n",
      " |  __init__(self, name, reader_cls, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __unicode__ = __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  unicode_repr = __repr__(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from nltk.corpus import movie_reviews\n",
    "help(movie_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the document  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Reviews: 2000\n",
      "Number of Positive review: 1000\n",
      "Number of Negative review: 1000\n"
     ]
    }
   ],
   "source": [
    "#loading moview_reviews\n",
    "#import nltk\n",
    "#nltk.download('movie_reviews')\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "print(\"Number of Reviews:\",len(documents))\n",
    "\n",
    "#This loaded document is a list of tokens eg-['don',''','t',i,movie,was,good]\n",
    "\n",
    "#For shuffling the document (not so important ,just to increase reproductibility)\n",
    "random.seed\n",
    "random.shuffle(documents)\n",
    "\n",
    "#list to store all review text and label\n",
    "text_data=[]\n",
    "label=[]\n",
    "for i in range(len(documents)):\n",
    "    text_data.append(' '.join(documents[i][0]))\n",
    "    label.append(0 if documents[i][1]=='neg' else 1)\n",
    "    \n",
    "print(\"Number of Positive review:\",label.count(1))\n",
    "print(\"Number of Negative review:\",label.count(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eddie murphy has a lot riding on harlem nights . as the movie ' s writer , director , executive producer , and star , murphy will shoulder all of the blame if harlem nights fails . but at the same time , he ' ll receive all of the credit if it succeeds . should you sacrifice your hard - earned cash to support murphy ' s risky gamble ? well , that depends on whom you trust more : me or eddie murphy . here ' s what murphy thinks : \" i think the audience is expecting a good time . they gonna get sexy . they gonna get funny . they gonna get drama . they gonna get all of that . i think it ' s the best movie i ' ve done \" ( paramount radio network ) . here ' s what i think : harlem nights is charmless , unoriginal , disappointing , and almost without question , the worst film of the actor ' s career ( i haven ' t seen best defense ) . and guess who ' s to blame ? ! the movie ' s problem is not murphy ' s direction : harlem nights is a fairly good looking film . no , the project was probably doomed even before the cameras rolled . murphy ' s awful script is the culprit . let ' s count the mistakes he makes in his first attempt at screenwriting : ( 1 ) murphy shatters the record for the most profanity in a motion picture . yes , he even outdoes his own work in raw . practically every line of dialogue in harlem nights contains at least one four letter word . and after 15 minutes , it gets irritating . ( 2 ) murphy wastes the talents of his fine cast . richard pryor , redd foxx , michael lerner , and della reese face the impossible task of carving out credible characters from a script riddled with stereotypes . each of them shines occasionally , but basically what we have are good performers stuck in a bad vehicle . ( 3 ) the movie demeans women by depicting them solely as sexual objects and as pawns in power struggles between men . murphy has admitted in interviews that he is weary of women in his private life , which is really neither here nor there . but when murphy puts his bitter feelings on 3 , 000 movie screens across the country , it ' s another matter altogether . you ' re forced to swallow some pretty gruesome stuff . for instance , murphy punches della reese in the stomach . and he shoots jasmine guy in the head . this is a mean - spirited movie , folks ! lovely newcomer lela rochon gets off easy in her role as a common whore , but only because she doesn ' t have any scenes with murphy . thank god : he might have run her over with a bulldozer . ( 4 ) murphy has written for himself perhaps his blandest role to date . the loveable eddie murphy charisma emerges only once or twice during the film . murphy would rather give his character a spiffy wardrobe than a spiffy personality . sometimes it seems as if murphy made harlem nights just so he could wear fancy suits and look debonair . ( 5 ) the plot is a shameless rip - off of the sting . if you ' re going to make another sting movie , you ' ve got to do something original . murphy ' s tale of warring nightclub owners in harlem ( circa 1938 ) fails to add anything new to the formula . ( 6 ) to get laughs , murphy makes fun of stuttering . you know a comedy is digging deep when it resorts to ridiculing the handicapped . ( 7 ) murphy ' s idea of drama is a scene in which his character apologizes for the first time in his life . for what ? for shooting reese ' s little toe off ! needless to say , murphy shows little , if any , promise or imagination as a screenwriter . in all fairness , however , a few rays of sunshine do manage to break through the gloomy cloud surrounding the movie . danny aiello is fun to watch as a dirty cop on the take . aiello stands out in the large , ensemble cast : he obviously relishes the opportunity to play such a nasty character ( a racist detective with mob ties ) . aiello ' s zesty performance gives harlem nights some much needed spice . another bright spot is arsenio hall , who has a hilarious , show - stopping cameo as a cry - baby gangster ; hall virtually steals the spotlight from murphy . in fact , hall ' s ten minutes on screen are the funniest ten minutes in the movie . unfortunately , his character is completely irrelevant to the plot ; murphy should have given hall a much bigger role . of course , i ' ve already mentioned that i didn ' t care for murphy ' s character , but i have to admit that i did love his neckties . they are simply spectacular -- almost worth the price of admission .\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(text_data,label,test_size=0.25,random_state=23)\n",
    "print(X_train[3])\n",
    "print()\n",
    "print(y_train[34])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Bag of words(DTM) ,Fitting the model , Calculating the Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Naive bayes: 78.8\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.72      0.89      0.80       238\n",
      "    Positive       0.88      0.69      0.77       262\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       500\n",
      "   macro avg       0.80      0.79      0.79       500\n",
      "weighted avg       0.81      0.79      0.79       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_cv=TfidfVectorizer(stop_words='english')\n",
    "train_dtm_tf=tf_cv.fit_transform(X_train)\n",
    "test_dtm_tf=tf_cv.transform(X_test)\n",
    "\n",
    "nb=MultinomialNB()\n",
    "nb=nb.fit(train_dtm_tf,y_train)\n",
    "predicted=nb.predict(test_dtm_tf)\n",
    "score=100.0* nb.score(test_dtm_tf,y_test)\n",
    "print(\"The accuracy of the Naive bayes:\",score)\n",
    "print(\"Classification Report:\")\n",
    "report=metrics.classification_report(y_test,predicted, target_names = ['Negative', 'Positive'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[213,  25],\n",
       "       [ 81, 181]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test,predicted)\n",
    "#confusion(y_test, y_pred, ['Negative', 'Positive'], 'Naive Bayes Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 20 positive words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['film', 'movie', 'like', 'life', 'story', 'good', 'just', 'time', 'character', 'characters', 'films', 'great', 'way', 'people', 'best', 'really', 'does', 'love', 'man', 'world']\n"
     ]
    }
   ],
   "source": [
    "all_words=np.array(tf_cv.get_feature_names())\n",
    "top_word_index=np.argsort(nb.coef_[0])[-20:]\n",
    "tn_lst=[word for word in all_words[top_word_index]]\n",
    "tn_lst.reverse()\n",
    "print(tn_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression: 84.39999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(C=1000)\n",
    "\n",
    "lr=lr.fit(train_dtm_tf,y_train)\n",
    "predicted=lr.predict(test_dtm_tf)\n",
    "scr = 100.0 * lr.score(test_dtm_tf, y_test)\n",
    "print(\"Accuracy of Logistic Regression:\",scr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 20 Positive Word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['great', 'fun', 'overall', 'life', 'memorable', 'definitely', 'quite', 'frank', 'performance', 'seen', 'excellent', 'hilarious', 'titanic', 'terrific', 'enjoyed', 'job', 'rob', 'family', 'different', 'performances']\n"
     ]
    }
   ],
   "source": [
    "top_word_index=np.argsort(lr.coef_[0])[-20:]\n",
    "tn_lst=[word for word in all_words[top_word_index]]\n",
    "tn_lst.reverse()\n",
    "print(tn_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 20 Negative Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Documents\\New folder\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bad', 'plot', 'unfortunately', 'boring', 'worst', 'reason', 'supposed', 'awful', 'poor', 'waste', 'stupid', 'script', 'ridiculous', 'fails', 'harry', 'dull', 'carpenter', 'terrible', 'mess', 'poorly']\n"
     ]
    }
   ],
   "source": [
    "y_train_reverse = [0 if y==1 else 1 for y in y_train]\n",
    "lr = lr.fit(train_dtm_tf, y_train_reverse)\n",
    "\n",
    "top_word_index = np.argsort(lr.coef_[0])[-20:]\n",
    "tn_lst = [word for word in all_words[top_word_index]]\n",
    "tn_lst.reverse()\n",
    "print(tn_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now using Stemming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As Countvectorizer and TF-IDF dont do stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-60ad57cf17e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mtf_cv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtrain_dtm_tf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mtest_dtm_tf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "import string,nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens=nltk.word_tokenize(text)\n",
    "    tokens=[token for token in tokens if token not in string.punctuation]\n",
    "    ps=PorterStemmer()\n",
    "    stems=map(stemmer.stem,tokens)\n",
    "    return stems\n",
    "\n",
    "tf_cv=TfidfVectorizer(tokenizer=tokenize)\n",
    "train_dtm_tf=tf_cv.fit_transform(X_train)\n",
    "test_dtm_tf=tf_cv.transform(X_test)\n",
    "\n",
    "lr=LogisticRegression(C=1000)\n",
    "lr=lr.fit(train_dtm_tf,y_train)\n",
    "predicted=lr.predict(test_dtm_tf)\n",
    "\n",
    "scr=100.0 * lr.score(test_dtm_tf,y_test)\n",
    "print(\"Accuracy after applying stemming:\",scr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
